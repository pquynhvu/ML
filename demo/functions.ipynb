{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u> **Setting up:** </u>\n",
    "\n",
    "* data: $\\tilde{X} \\in \\mathbb{R}^{n \\times d}$ (n data points and d features)\n",
    "\n",
    "* labels: $\\tilde{Y} \\in \\mathbb{R}^{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random linear classifier (w/ 0-1 loss):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_linear_classifier(data, label, k): # k is the number of max iterations\n",
    "    n, d = data.shape\n",
    "    loss = []\n",
    "    \n",
    "    for t in range(k):\n",
    "        theta = np.random.rand(d, 1)\n",
    "        theta_null = np.random.rand(1,)\n",
    "        h = []\n",
    "        for i in range(n):\n",
    "            z = np.matmul(theta.T, data[i,:]) + theta_null\n",
    "            h.append(np.sign(z)[0][0])\n",
    "    \n",
    "        loss = np.mean()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perceptrons w/ offset term:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_with_offset(data, labels, tau):      # tau is the number of iterations\n",
    "    n, d = data.shape                   \n",
    "    theta = np.zeros(d).reshape(d,1)\n",
    "    theta_0 = np.zeros(1)\n",
    "    no_mistakes = 0\n",
    "\n",
    "    print(\"The data set has {} features, {} data points.\\n\".format(d,n))\n",
    "    \n",
    "    for t in range(tau):\n",
    "        changed = False\n",
    "        for i in range(n):\n",
    "            y = labels[i]\n",
    "            x = data[i,:].reshape(d, 1)\n",
    "            if np.sign(y*(np.matmul(theta.T,x) + theta_0)) <= 0:\n",
    "                no_mistakes +=1\n",
    "                theta = theta + y*x\n",
    "                theta_0 = theta_0 + y\n",
    "                changed = True\n",
    "        if changed==False:\n",
    "            break\n",
    "    print(\"After {} mistake(s), the Perceptron Algorithm (w/ offset) yields theta = {}, theta_0 = {} on the {}th instance\\n\".format(no_mistakes, theta, theta_0, i))\n",
    "    return theta, theta_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perceptron through the origin:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_through_origin(data, labels, tau):      # tau is the number of iterations\n",
    "    n, d = data.shape    \n",
    "    data_new = np.append(data, np.ones((n, 1)), axis=1)\n",
    "    theta = np.zeros(d+1).reshape(d+1,1)\n",
    "    no_mistakes = 0\n",
    "\n",
    "    print(\"The data set has {} features and {} data points.\\n\".format(d,n))\n",
    "    \n",
    "    for t in range(tau):\n",
    "        changed = False\n",
    "        for i in range(n):\n",
    "            y = labels[i]\n",
    "            x = data_new[i,:].reshape(d+1, 1)\n",
    "            if np.sign(y*(np.matmul(theta.T,x))) <= 0:\n",
    "                theta = theta + y*x\n",
    "                no_mistakes +=1\n",
    "                changed = True\n",
    "        if changed==False:\n",
    "            break\n",
    "    print(\"After {} mistake(s), the Perceptron Algorithm (through the origin) yields theta = {} on the {}th instance\".format(no_mistakes, theta, i))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Averaged Perceptron:**\n",
    "\n",
    "* Instead of using all weight vectors, use the average weight vector (i.e longer surviving weight vectors get more say)\n",
    "\n",
    "* More practical alternative and widely used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaged_perceptron(data, labels, tau):\n",
    "    n, d = data.shape\n",
    "    theta = np.zeros((d,1))\n",
    "    theta_0 = np.zeros(1)\n",
    "    ths = np.zeros((d,1))\n",
    "    th0s = np.zeros(1)\n",
    "    no_mistakes = 0\n",
    "    print(\"The data set has {} features and {} data points \\n\".format(d,n))\n",
    "  \n",
    "    for t in range(tau):   \n",
    "      changed = False  \n",
    "      for i in range(n):\n",
    "        y = labels[i]\n",
    "        x = data[i,:].reshape(d,1)\n",
    "        \n",
    "        if np.sign(y*(np.matmul(theta.T,x) + theta_0)) <= 0:\n",
    "          theta += y*x\n",
    "          theta_0 += y\n",
    "          no_mistakes +=1\n",
    "          changed = True\n",
    "          \n",
    "        ths += theta\n",
    "        th0s += theta_0\n",
    "      if changed==False:\n",
    "        no_mistakes +=0\n",
    "        break\n",
    "        \n",
    "    print(\"After {} mistake(s), the Averaged Perceptron algorithm yields theta = {}, theta_0 = {} on the {}th instance\".format(no_mistakes, ths/(n*tau),th0s/(n*tau), i))\n",
    "    return (ths/(n*tau),th0s/(n*tau))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross-validation:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Descent:**\n",
    "\n",
    "- $\\theta_{init}$ $\\in$ $\\mathbb{R}^{m}$\n",
    "\n",
    "- $\\theta$ $\\in$ $\\mathbb{R}^{m}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feval(f, x, y):\n",
    "    return eval(f)\n",
    "\n",
    "def gradient_descent(theta_init, eta, epsilon, T, func={}, derivative={}):            # enter theta_init as a list\n",
    "    m = len(theta_init)\n",
    "    # One-dimension case:\n",
    "    if m == 1: \n",
    "        f=func.get('f',input('Enter the function f(x) ='))\n",
    "        df=derivative.get('df', input('Enter the function df(x) ='))\n",
    "    \n",
    "        t = 0\n",
    "        theta = np.array([theta_init])\n",
    "        f_ = np.array([feval(f, theta[t], 0)])\n",
    "    \n",
    "        while True:\n",
    "            t +=1\n",
    "            theta = np.append(theta, theta[t-1]-eta*feval(df, theta[t-1], 0))\n",
    "            f_ = np.append(f_,feval(f, theta[t], 0))\n",
    "            if abs(feval(f,theta[t], 0)-feval(f, theta[t-1], 0)) < epsilon:\n",
    "                break\n",
    "    # Two-dimension case:\n",
    "    elif m ==2:\n",
    "        f=func.get('f',input('Enter the function f(x, y) ='))\n",
    "        df_x=derivative.get('df', input('Enter the function df(x) ='))\n",
    "        df_y=derivative.get('df', input('Enter the function df(y) ='))\n",
    "    \n",
    "        t = 0\n",
    "        theta = np.array([theta_init]).reshape(m,1)\n",
    "        f_ = np.array([feval(f, theta[0, t], theta[1, t])])\n",
    "    \n",
    "        while True:\n",
    "            t +=1\n",
    "            theta = np.append(theta, theta[:,t-1].reshape(m,1) - eta*np.array([feval(df_x, theta[0,t-1], 0), feval(df_y, 0, theta[1,t-1])]).reshape(m,1), axis=1)\n",
    "            f_ = np.append(f_, feval(f, theta[0,t], theta[1,t]))\n",
    "            if t > T:\n",
    "                break\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return theta, f_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression Gradient Descent:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stochastic Gradient Descent:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(theta_init):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
